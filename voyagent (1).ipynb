{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9R5KQmXosLs"
      },
      "outputs": [],
      "source": [
        "# ===================================================================\n",
        "# COMPLETE VOICE AGENT WITH MURF WEBSOCKET - COLAB READY (V5)\n",
        "# - Uses Colab register_callback for stable voice input -\n",
        "# ===================================================================\n",
        "\n",
        "# --- CELL 1: DEPENDENCY INSTALLATION ---\n",
        "# NOTE: Run this cell block entirely!\n",
        "\n",
        "# Install system dependencies (ffmpeg is needed by pydub, portaudio for pyaudio)\n",
        "!apt install ffmpeg portaudio19-dev -y -qq\n",
        "\n",
        "# Install Python libraries, including the crucial nest-asyncio fix, Google STT, and SciPy\n",
        "!pip install google-genai websockets pyaudio pydub numpy nest-asyncio google-cloud-speech scipy -q\n",
        "\n",
        "# --- CELL 2: COMPLETE CODE ---\n",
        "\n",
        "import os\n",
        "import io\n",
        "import re\n",
        "import json\n",
        "import base64\n",
        "import asyncio\n",
        "import wave\n",
        "import struct\n",
        "import numpy as np\n",
        "import nest_asyncio\n",
        "from typing import Literal, Optional, List, Dict\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from IPython.display import display, Markdown, Audio as IPAudio, HTML\n",
        "from google.colab import userdata, output\n",
        "from pydub import AudioSegment\n",
        "import pyaudio\n",
        "import websockets\n",
        "# NEW IMPORTS FOR SPEECH-TO-TEXT (STT) and WAV handling\n",
        "from google.cloud import speech_v1p1beta1 as speech\n",
        "from google.oauth2 import service_account\n",
        "from scipy.io.wavfile import write as write_wav\n",
        "\n",
        "# ===================================================================\n",
        "# INITIALIZATION\n",
        "# ===================================================================\n",
        "\n",
        "print(\"üöÄ Initializing Voice Agent System...\\n\")\n",
        "\n",
        "# Initialize Gemini\n",
        "try:\n",
        "    gemini_key = userdata.get('GEMINI_API_KEY')\n",
        "    if gemini_key:\n",
        "        os.environ['GEMINI_API_KEY'] = gemini_key\n",
        "        GEMINI_CLIENT = genai.Client()\n",
        "        print(\"‚úÖ Gemini initialized\")\n",
        "    else:\n",
        "        GEMINI_CLIENT = None\n",
        "        print(\"‚ùå GEMINI_API_KEY not found\")\n",
        "except Exception as e:\n",
        "    GEMINI_CLIENT = None\n",
        "    print(f\"‚ùå Gemini error: {e}\")\n",
        "\n",
        "# Get Murf API Key\n",
        "try:\n",
        "    MURF_API_KEY = userdata.get('MURF_API_KEY')\n",
        "    if MURF_API_KEY:\n",
        "        print(\"‚úÖ Murf API key loaded\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è ¬†MURF_API_KEY not found - TTS will not work\")\n",
        "        MURF_API_KEY = None\n",
        "except:\n",
        "    MURF_API_KEY = None\n",
        "    print(\"‚ö†Ô∏è ¬†MURF_API_KEY not found\")\n",
        "\n",
        "# Fix for Colab: Allow asyncio.run to be called from a running event loop\n",
        "try:\n",
        "    nest_asyncio.apply()\n",
        "    print(\"‚úÖ nest_asyncio applied (Fixes TTS failure)\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå nest_asyncio error: {e}\")\n",
        "\n",
        "# Global variables for callback communication\n",
        "CALLBACK_DATA = {}\n",
        "CALLBACK_EVENT = asyncio.Event()\n",
        "\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ===================================================================\n",
        "# STORY GENERATION\n",
        "# ===================================================================\n",
        "\n",
        "def generate_story(topic: str, language: str, age_mode: str, length_min: int):\n",
        "    \"\"\"Generate structured story with Gemini\"\"\"\n",
        "    if not GEMINI_CLIENT:\n",
        "        print(\"‚ùå Gemini not initialized\")\n",
        "        return None\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You are a storyteller. Generate stories in tagged format. \"\n",
        "        \"Each line: <EMOTION:tag> <SFX:effect> Story text. \"\n",
        "        \"First line: <TITLE:title>\"\n",
        "    )\n",
        "\n",
        "    segments = max(4, length_min * 3)\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "Create a {language} story about: '{topic}'\n",
        "Audience: {age_mode}\n",
        "Length: {length_min} minutes (~{segments} segments)\n",
        "\n",
        "Format:\n",
        "<TITLE:Story Title>\n",
        "<EMOTION:calm> <SFX:wind> Story text here.\n",
        "<EMOTION:happy> <SFX:None> More story text.\n",
        "\n",
        "Emotions: calm, happy, adventurous, sad, mystery, excitement, cinematic\n",
        "Generate {segments} segments. Keep each segment 2-3 sentences.\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = GEMINI_CLIENT.models.generate_content(\n",
        "            model='gemini-2.0-flash-exp',\n",
        "            contents=user_prompt,\n",
        "            config=types.GenerateContentConfig(\n",
        "                system_instruction=system_prompt,\n",
        "                temperature=0.7,\n",
        "                max_output_tokens=4096\n",
        "            )\n",
        "        )\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Story generation failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def parse_story(raw_text: str):\n",
        "    \"\"\"Parse story into segments\"\"\"\n",
        "    lines = [l.strip() for l in raw_text.split('\\n') if l.strip()]\n",
        "\n",
        "    if not lines:\n",
        "        return \"Untitled\", []\n",
        "\n",
        "    title_match = re.match(r'<TITLE:(.*?)>', lines[0], re.IGNORECASE)\n",
        "    title = title_match.group(1).strip() if title_match else \"Untitled Story\"\n",
        "    story_lines = lines[1:] if title_match else lines\n",
        "\n",
        "    segments = []\n",
        "    regex = re.compile(r'<EMOTION:(.*?)>\\s*<SFX:(.*?)>\\s*(.*)')\n",
        "\n",
        "    for i, line in enumerate(story_lines):\n",
        "        match = regex.match(line)\n",
        "        if match:\n",
        "            segments.append({\n",
        "                'id': i,\n",
        "                'emotion': match.group(1).strip(),\n",
        "                'sfx': match.group(2).strip(),\n",
        "                'text': match.group(3).strip()\n",
        "            })\n",
        "\n",
        "    return title, segments\n",
        "\n",
        "# ===================================================================\n",
        "# COLAB AUDIO RECORDING FUNCTION (FIXED with register_callback)\n",
        "# ===================================================================\n",
        "\n",
        "def audio_callback(data):\n",
        "    \"\"\"Called by the JavaScript when recording is complete.\"\"\"\n",
        "    global CALLBACK_DATA\n",
        "    global CALLBACK_EVENT\n",
        "    CALLBACK_DATA = data\n",
        "    CALLBACK_EVENT.set() # Signal that data is ready\n",
        "\n",
        "def record_audio_colab(filename='audio.wav', duration_sec=8, sample_rate=24000):\n",
        "    \"\"\"\n",
        "    Records audio using the Colab/IPython microphone widget.\n",
        "    Saves the result as a WAV file.\n",
        "    \"\"\"\n",
        "    global CALLBACK_DATA\n",
        "    global CALLBACK_EVENT\n",
        "\n",
        "    # 1. Reset communication variables\n",
        "    CALLBACK_DATA = {}\n",
        "    CALLBACK_EVENT.clear()\n",
        "\n",
        "    # 2. Register the Python function to be called by JavaScript\n",
        "    output.register_callback('notebook.audio_callback', audio_callback)\n",
        "\n",
        "    print(f\"üé§ Recording {duration_sec} seconds via Colab widget...\")\n",
        "    display(HTML(\"\"\"\n",
        "        <script>\n",
        "            const record = async (duration, sampleRate, filename) => {\n",
        "                const stream = await navigator.mediaDevices.getUserMedia({audio: true});\n",
        "                const audioContext = new AudioContext({sampleRate: sampleRate});\n",
        "                const mediaRecorder = new MediaRecorder(stream);\n",
        "                const audioChunks = [];\n",
        "\n",
        "                mediaRecorder.ondataavailable = event => audioChunks.push(event.data);\n",
        "\n",
        "                const data = new Promise(resolve => {\n",
        "                    mediaRecorder.onstop = () => {\n",
        "                        const audioBlob = new Blob(audioChunks, {type: 'audio/wav'});\n",
        "                        const fileReader = new FileReader();\n",
        "                        fileReader.onload = () => resolve(fileReader.result.split(',')[1]);\n",
        "                        fileReader.readAsDataURL(audioBlob);\n",
        "                    };\n",
        "                    mediaRecorder.start();\n",
        "                    setTimeout(() => mediaRecorder.stop(), duration * 1000);\n",
        "                });\n",
        "\n",
        "                const base64Data = await data;\n",
        "\n",
        "                // Call the registered Python function back with the data\n",
        "                google.colab.kernel.invokeFunction('notebook.audio_callback', [\n",
        "                    {'record_data': base64Data, 'record_filename': filename}\n",
        "                ], {});\n",
        "            };\n",
        "\n",
        "            // Invoke the record function with parameters\n",
        "            record(%d, %d, '%s');\n",
        "\n",
        "            // Display recording controls\n",
        "            document.querySelector('#record-status').innerText = 'üî¥ Recording... Speak Now! (Wait for completion message)';\n",
        "        </script>\n",
        "        <div id=\"record-status\">Click RUN to start recording.</div>\n",
        "    \"\"\" % (duration_sec, sample_rate, filename)))\n",
        "\n",
        "    # 3. Wait for the JavaScript callback to signal data readiness (asyncio.run is safe due to nest_asyncio)\n",
        "    try:\n",
        "        asyncio.run(asyncio.wait_for(CALLBACK_EVENT.wait(), timeout=duration_sec + 5))\n",
        "    except asyncio.TimeoutError:\n",
        "        print(\"‚ùå Recording timed out while waiting for user input.\")\n",
        "        return None\n",
        "\n",
        "    # 4. Process data from the global variable\n",
        "    if 'record_data' in CALLBACK_DATA:\n",
        "        base64_data = CALLBACK_DATA['record_data']\n",
        "        file_data = base64.b64decode(base64_data)\n",
        "\n",
        "        # Save the raw data as the specified WAV file\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(file_data)\n",
        "\n",
        "        print(f\"‚úÖ Colab recording complete and saved as {filename}\")\n",
        "        return filename\n",
        "    else:\n",
        "        print(\"‚ùå Colab recording failed or data not received.\")\n",
        "        return None\n",
        "\n",
        "# ===================================================================\n",
        "# SPEECH-TO-TEXT (STT)\n",
        "# ===================================================================\n",
        "\n",
        "def transcribe_audio(file_path: str) -> Optional[str]:\n",
        "    \"\"\"Transcribe a local audio file using Google Cloud Speech-to-Text.\"\"\"\n",
        "    print(\"üß† Transcribing audio with Google STT...\")\n",
        "    try:\n",
        "        # 1. Load the audio file content\n",
        "        with io.open(file_path, \"rb\") as audio_file:\n",
        "            content = audio_file.read()\n",
        "\n",
        "        audio = speech.RecognitionAudio(content=content)\n",
        "\n",
        "        # 2. Configure the transcription request\n",
        "        config = speech.RecognitionConfig(\n",
        "            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16, # WAV format\n",
        "            sample_rate_hertz=24000, # Matches your recording rate\n",
        "            language_code=\"en-IN\",\n",
        "        )\n",
        "\n",
        "        # 3. Initialize and run the client (requires authentication)\n",
        "        stt_client = speech.SpeechClient()\n",
        "        response = stt_client.recognize(config=config, audio=audio)\n",
        "\n",
        "        if not response.results:\n",
        "            print(\"‚ùå STT failed: No speech detected in the audio.\")\n",
        "            return None\n",
        "\n",
        "        # 4. Get the best transcription result\n",
        "        transcript = response.results[0].alternatives[0].transcript\n",
        "        print(f\"‚úÖ Transcription: '{transcript}'\")\n",
        "        return transcript\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Transcription failed (Is Google STT API enabled and authenticated?): {e}\")\n",
        "        return None\n",
        "\n",
        "# ===================================================================\n",
        "# MURF WEBSOCKET TTS (REAL IMPLEMENTATION)\n",
        "# ===================================================================\n",
        "\n",
        "EMOTION_TO_STYLE = {\n",
        "    'calm': 'Conversation',\n",
        "    'happy': 'Conversation',\n",
        "    'adventurous': 'Conversation',\n",
        "    'sad': 'Conversation',\n",
        "    'mystery': 'Conversation',\n",
        "    'excitement': 'Conversation',\n",
        "    'cinematic': 'Conversation',\n",
        "    'default': 'Conversation'\n",
        "}\n",
        "\n",
        "async def murf_tts_websocket(text: str, emotion: str = \"calm\",\n",
        "                             voice_id: str = \"Anisha\") -> bytes:\n",
        "    \"\"\"\n",
        "    Generate TTS using Murf WebSocket API (REAL IMPLEMENTATION)\n",
        "    Returns audio bytes\n",
        "    \"\"\"\n",
        "    if not MURF_API_KEY:\n",
        "        raise Exception(\"MURF_API_KEY not set\")\n",
        "\n",
        "    WS_URL = (\n",
        "        f\"wss://global.api.murf.ai/v1/speech/stream-input?\"\n",
        "        f\"api-key={MURF_API_KEY}&\"\n",
        "        f\"model=FALCON&\"\n",
        "        f\"sample_rate=24000&\"\n",
        "        f\"channel_type=MONO&\"\n",
        "        f\"format=WAV\"\n",
        "    )\n",
        "\n",
        "    style = EMOTION_TO_STYLE.get(emotion.lower(), 'Conversation')\n",
        "\n",
        "    all_audio_bytes = b\"\"\n",
        "    first_chunk = True\n",
        "\n",
        "    try:\n",
        "        async with websockets.connect(WS_URL) as ws:\n",
        "            # Send voice configuration\n",
        "            voice_config = {\n",
        "                \"voice_config\": {\n",
        "                    \"voiceId\": voice_id,\n",
        "                    \"multiNativeLocale\": \"en-IN\",\n",
        "                    \"style\": style,\n",
        "                    \"rate\": 0,\n",
        "                    \"pitch\": 0,\n",
        "                    \"variation\": 1\n",
        "                }\n",
        "            }\n",
        "            await ws.send(json.dumps(voice_config))\n",
        "\n",
        "            # Send text\n",
        "            text_msg = {\n",
        "                \"text\": text,\n",
        "                \"end\": True\n",
        "            }\n",
        "            await ws.send(json.dumps(text_msg))\n",
        "\n",
        "            # Receive audio chunks\n",
        "            while True:\n",
        "                response = await ws.recv()\n",
        "                data = json.loads(response)\n",
        "\n",
        "                if \"audio\" in data:\n",
        "                    audio_bytes = base64.b64decode(data[\"audio\"])\n",
        "\n",
        "                    # Skip WAV header for first chunk only\n",
        "                    if first_chunk and len(audio_bytes) > 44:\n",
        "                        audio_bytes = audio_bytes[44:]\n",
        "                        first_chunk = False\n",
        "\n",
        "                    all_audio_bytes += audio_bytes\n",
        "\n",
        "                if data.get(\"final\"):\n",
        "                    break\n",
        "\n",
        "        return all_audio_bytes\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Murf WebSocket error: {e}\")\n",
        "        raise\n",
        "\n",
        "def text_to_speech_sync(text: str, emotion: str) -> AudioSegment:\n",
        "    \"\"\"Synchronous wrapper for async TTS\"\"\"\n",
        "    try:\n",
        "        audio_bytes = asyncio.run(murf_tts_websocket(text, emotion))\n",
        "\n",
        "        if not audio_bytes:\n",
        "            raise Exception(\"No audio received\")\n",
        "\n",
        "        # Convert raw PCM to AudioSegment\n",
        "        audio = AudioSegment(\n",
        "            data=audio_bytes,\n",
        "            sample_width=2,  # 16-bit\n",
        "            frame_rate=24000,\n",
        "            channels=1\n",
        "        )\n",
        "\n",
        "        return audio\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è ¬†TTS failed: {e}, using silence\")\n",
        "        duration = len(text) * 50\n",
        "        return AudioSegment.silent(duration=duration, frame_rate=24000)\n",
        "\n",
        "# ===================================================================\n",
        "# REAL-TIME AUDIO CLEANUP\n",
        "# ===================================================================\n",
        "\n",
        "class RealTimeAudio:\n",
        "    \"\"\"Handle audio cleanup and optional pyaudio playback (not used for recording)\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.CHUNK = 1024\n",
        "        self.FORMAT = pyaudio.paInt16\n",
        "        self.CHANNELS = 1\n",
        "        self.RATE = 24000  # Match Murf output\n",
        "        # Initialize pyaudio only if needed for playback or cleanup\n",
        "        try:\n",
        "            self.p = pyaudio.PyAudio()\n",
        "        except:\n",
        "             self.p = None\n",
        "        self.frames = []\n",
        "\n",
        "    def play_audio_realtime(self, audio_segment: AudioSegment):\n",
        "        \"\"\"Stream audio playback in real-time with proper format (optional, may fail)\"\"\"\n",
        "        if not self.p:\n",
        "            print(\"üîä PyAudio not initialized. Skipping real-time playback.\")\n",
        "            return\n",
        "\n",
        "        print(\"üîä Playing audio in real-time...\")\n",
        "\n",
        "        audio_segment = audio_segment.set_frame_rate(self.RATE).set_channels(self.CHANNELS).set_sample_width(2)\n",
        "        raw_data = audio_segment.raw_data\n",
        "\n",
        "        stream = self.p.open(format=self.FORMAT, channels=self.CHANNELS, rate=self.RATE, output=True)\n",
        "        chunk_size = self.CHUNK * 2\n",
        "\n",
        "        for i in range(0, len(raw_data), chunk_size):\n",
        "            chunk = raw_data[i:i+chunk_size]\n",
        "            stream.write(chunk)\n",
        "\n",
        "            if i % (chunk_size * 20) == 0:\n",
        "                progress = int((i / len(raw_data)) * 30)\n",
        "                bar = \"‚ñà\" * progress + \"‚ñë\" * (30 - progress)\n",
        "                print(f\"\\r ¬† [{bar}]\", end=\"\", flush=True)\n",
        "\n",
        "        print(\"\\r ¬† [\" + \"‚ñà\"*30 + \"]\")\n",
        "        stream.stop_stream()\n",
        "        stream.close()\n",
        "        print(\"‚úÖ Playback complete!\")\n",
        "\n",
        "    def cleanup(self):\n",
        "        \"\"\"Clean up resources\"\"\"\n",
        "        if self.p:\n",
        "            self.p.terminate()\n",
        "\n",
        "# ===================================================================\n",
        "# COMPLETE AUDIOBOOK PIPELINE\n",
        "# ===================================================================\n",
        "\n",
        "def create_audiobook(topic: str, language: str = \"English\",\n",
        "                     age_mode: str = \"kids\", length_min: int = 2):\n",
        "    \"\"\"Complete pipeline: Story ‚Üí TTS ‚Üí Audio file\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üé¨ CREATING {age_mode.upper()} AUDIOBOOK\")\n",
        "    print(f\" ¬† Topic: {topic}\")\n",
        "    print(f\" ¬† Length: {length_min} minutes\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # 1. Generate story\n",
        "    print(\"üìù Step 1: Generating story with Gemini...\")\n",
        "    raw_story = generate_story(topic, language, age_mode, length_min)\n",
        "    if not raw_story:\n",
        "        return None\n",
        "\n",
        "    # 2. Parse\n",
        "    print(\"\\nüìñ Step 2: Parsing story structure...\")\n",
        "    title, segments = parse_story(raw_story)\n",
        "    print(f\" ¬† ‚úì Title: {title}\")\n",
        "    print(f\" ¬† ‚úì Segments: {len(segments)}\")\n",
        "\n",
        "    if not segments:\n",
        "        print(\"‚ùå No segments found\")\n",
        "        return None\n",
        "\n",
        "    # Preview\n",
        "    print(\"\\n ¬† Preview:\")\n",
        "    for seg in segments[:3]:\n",
        "        print(f\" ¬† ¬† ¬†[{seg['id']}] {seg['emotion']}: {seg['text'][:50]}...\")\n",
        "    if len(segments) > 3:\n",
        "        print(f\" ¬† ¬† ¬†... and {len(segments)-3} more segments\")\n",
        "\n",
        "    # 3. Generate TTS for each segment\n",
        "    print(f\"\\nüéôÔ∏è ¬†Step 3: Generating audio with Murf WebSocket (Voice: Anisha)...\")\n",
        "\n",
        "    full_audio = AudioSegment.empty()\n",
        "\n",
        "    for i, seg in enumerate(segments):\n",
        "        print(f\" ¬† [{i+1}/{len(segments)}] {seg['emotion']}: \", end=\"\", flush=True)\n",
        "\n",
        "        try:\n",
        "            audio = text_to_speech_sync(seg['text'], seg['emotion'])\n",
        "            full_audio += audio\n",
        "\n",
        "            full_audio += AudioSegment.silent(duration=800, frame_rate=24000)\n",
        "\n",
        "            duration = len(audio) / 1000.0\n",
        "            print(f\"‚úì ({duration:.1f}s)\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚úó Error: {e}\")\n",
        "\n",
        "    # 4. Export\n",
        "    os.makedirs(\"output\", exist_ok=True)\n",
        "    filename = title.replace(' ', '_').replace('/', '-')[:50]\n",
        "    output_file = f\"output/{filename}.mp3\"\n",
        "\n",
        "    print(f\"\\nüíæ Step 4: Exporting audiobook...\")\n",
        "    full_audio.export(output_file, format=\"mp3\", bitrate=\"128k\")\n",
        "\n",
        "    total_duration = len(full_audio) / 1000.0\n",
        "    print(f\" ¬† ‚úì File: {output_file}\")\n",
        "    print(f\" ¬† ‚úì Duration: {total_duration:.1f}s ({total_duration/60:.1f} min)\")\n",
        "\n",
        "    # 5. Display player\n",
        "    print(f\"\\nüéâ SUCCESS! Playing audiobook...\")\n",
        "    display(IPAudio(output_file, autoplay=False))\n",
        "\n",
        "    return output_file\n",
        "\n",
        "# ===================================================================\n",
        "# NEW PIPELINE FUNCTION (VOICE PROMPT)\n",
        "# ===================================================================\n",
        "\n",
        "def create_audiobook_from_voice_prompt(language: str = \"English\", age_mode: str = \"kids\", length_min: int = 2):\n",
        "    \"\"\"Complete pipeline: Voice Prompt ‚Üí STT ‚Üí Story ‚Üí TTS ‚Üí Audio file\"\"\"\n",
        "\n",
        "    audio_sys = RealTimeAudio()\n",
        "    recording_filename = \"user_prompt.wav\"\n",
        "\n",
        "    try:\n",
        "        # A. VOICE INPUT & RECORDING (Using Colab Native Recorder)\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"üó£Ô∏è ¬†START: Please state the topic for your story in a clear voice.\")\n",
        "        print(f\" ¬† Recording will start below and last 8 seconds.\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        recorded_file = record_audio_colab(\n",
        "            filename=recording_filename,\n",
        "            duration_sec=8,\n",
        "            sample_rate=24000\n",
        "        )\n",
        "\n",
        "        if not recorded_file:\n",
        "             print(\"‚ùå Recording failed, stopping.\")\n",
        "             return None\n",
        "\n",
        "        # B. TRANSCRIPTION (STT)\n",
        "        topic_prompt = transcribe_audio(recording_filename)\n",
        "\n",
        "        if not topic_prompt:\n",
        "            print(\"‚ùå Cannot proceed without a topic.\")\n",
        "            return None\n",
        "\n",
        "        # C. STORY GENERATION & TTS (Reuse existing function)\n",
        "        print(f\"\\n‚úÖ Topic received: '{topic_prompt}'\")\n",
        "        result_file = create_audiobook(\n",
        "            topic=topic_prompt,\n",
        "            language=language,\n",
        "            age_mode=age_mode,\n",
        "            length_min=length_min\n",
        "        )\n",
        "\n",
        "        return result_file\n",
        "\n",
        "    finally:\n",
        "        audio_sys.cleanup()\n",
        "\n",
        "# ===================================================================\n",
        "# USAGE EXAMPLES\n",
        "# ===================================================================\n",
        "\n",
        "def example_1_kids_story():\n",
        "    \"\"\"Example 1: Create a kids story\"\"\"\n",
        "    return create_audiobook(\n",
        "        topic=input(\"Enter the topic:\"),\n",
        "        language=input(\"Enter the language:\"),\n",
        "        age_mode=input(\"kids or teen or adult:\"),\n",
        "        length_min=int(input(\"time duration:\"))\n",
        "    )\n",
        "\n",
        "def example_2_record_audio():\n",
        "    \"\"\"Example 2: Record 10 seconds of audio and play it back\"\"\"\n",
        "    audio_sys = RealTimeAudio()\n",
        "    recording_file = \"my_voice.wav\"\n",
        "\n",
        "    file = record_audio_colab(filename=recording_file, duration_sec=10, sample_rate=24000)\n",
        "    if not file:\n",
        "        audio_sys.cleanup()\n",
        "        return None\n",
        "\n",
        "    audio_seg = AudioSegment.from_wav(file)\n",
        "\n",
        "    print(f\"\\nüìä Audio Info:\")\n",
        "    print(f\" ¬† Duration: {len(audio_seg)/1000:.1f}s\")\n",
        "    print(f\" ¬† Sample Rate: {audio_seg.frame_rate}Hz\")\n",
        "\n",
        "    audio_sys.play_audio_realtime(audio_seg)\n",
        "\n",
        "    print(\"\\nüñ•Ô∏è ¬†HTML5 Player (Guaranteed Playback):\")\n",
        "    display(IPAudio(file, autoplay=False))\n",
        "\n",
        "    audio_sys.cleanup()\n",
        "    return file\n",
        "\n",
        "def example_3_teen_story():\n",
        "    \"\"\"Example 3: Teen adventure story\"\"\"\n",
        "    return create_audiobook(\n",
        "        topic=\"friends discovering a mysterious portal in an ancient library\",\n",
        "        age_mode=\"teen\",\n",
        "        length_min=2\n",
        "    )\n",
        "\n",
        "def example_4_test_tts():\n",
        "    \"\"\"Example 4: Test Murf TTS directly\"\"\"\n",
        "    print(\"üß™ Testing Murf TTS WebSocket (Voice: Anisha)...\")\n",
        "\n",
        "    test_text = \"Hello! This is a test of the Murf text to speech system using the Anisha Indian English voice. It should sound clear!\"\n",
        "\n",
        "    try:\n",
        "        audio = text_to_speech_sync(test_text, \"happy\")\n",
        "        print(f\"‚úÖ TTS Success! Generated {len(audio)/1000:.1f}s of audio\")\n",
        "\n",
        "        audio.export(\"test_tts.mp3\", format=\"mp3\")\n",
        "        display(IPAudio(\"test_tts.mp3\", autoplay=True))\n",
        "\n",
        "        return \"test_tts.mp3\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå TTS Test Failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def example_5_voice_story():\n",
        "    \"\"\"Example 5: Record voice prompt and generate story\"\"\"\n",
        "    return create_audiobook_from_voice_prompt(\n",
        "        age_mode=\"kids\",\n",
        "        length_min=1\n",
        "    )\n",
        "\n",
        "# ===================================================================\n",
        "# READY TO USE\n",
        "# ===================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚ú® VOICE AGENT READY! (Using Anisha - Indian English)\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nüìö Available Examples:\")\n",
        "print(\" ¬†1. example_1_kids_story() ¬† - Create 2min kids story (Default Topic)\")\n",
        "print(\" ¬†2. example_2_record_audio() - Record 10s & playback (Colab-native recording)\")\n",
        "print(\" ¬†3. example_3_teen_story() ¬† - Create 2min teen story\")\n",
        "print(\" ¬†4. example_4_test_tts() ¬† ¬† - Test Murf TTS directly (Anisha voice test)\")\n",
        "print(\" ¬†5. example_5_voice_story() ¬†- **Record voice prompt and generate story**\")\n",
        "print(\"\\nüí° Quick Start:\")\n",
        "print(\" ¬†result = example_5_voice_story()\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# UNCOMMENT TO RUN:\n",
        "result = example_1_kids_story()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24DDIOIVXIFO"
      },
      "outputs": [],
      "source": [
        "# Colab cell (code)\n",
        "!apt-get update -qq\n",
        "!apt-get install -y ffmpeg\n",
        "!pip install soundfile librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-0QHgeJZmyV"
      },
      "outputs": [],
      "source": [
        "# Colab cell (code)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # Use the chooser that appears to upload sample_voice_raw.wav/mp3\n",
        "print(\"Uploaded:\", uploaded.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHGrtnetaNm7"
      },
      "outputs": [],
      "source": [
        "import os, glob, subprocess\n",
        "\n",
        "# Find uploaded file\n",
        "files = glob.glob('*sample_voice_raw*')\n",
        "if not files:\n",
        "    # Add .mpeg to the search patterns to correctly identify the uploaded file\n",
        "    files = glob.glob('*.wav') + glob.glob('*.mp3') + glob.glob('*.mpeg')\n",
        "\n",
        "# Check if any suitable file was found\n",
        "if not files:\n",
        "    raise FileNotFoundError(\"No suitable audio file found. Please upload a .wav, .mp3, or .mpeg file or ensure 'sample_voice_raw' is in the filename.\")\n",
        "\n",
        "input_file = files[0]\n",
        "print(\"Using input:\", input_file)\n",
        "\n",
        "# Convert to mono 22050Hz wav and normalize loudness\n",
        "output_file = \"sample_voice.wav\"\n",
        "cmd = f'ffmpeg -y -i \"{input_file}\" -ar 22050 -ac 1 -af \"loudnorm=I=-16:TP=-1.5:LRA=11\" \"{output_file}\"'\n",
        "print(cmd)\n",
        "subprocess.run(cmd, shell=True, check=True)\n",
        "print(\"Converted ->\", output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOMu5NOwaWjc"
      },
      "outputs": [],
      "source": [
        "# Colab cell (code)\n",
        "import IPython.display as ipd\n",
        "from scipy.io import wavfile\n",
        "import numpy as np\n",
        "\n",
        "sr, wav = wavfile.read(\"sample_voice.wav\")\n",
        "print(\"Sample rate:\", sr, \"Length (s):\", len(wav)/sr)\n",
        "ipd.display(ipd.Audio(\"sample_voice.wav\"))\n",
        "\n",
        "# crude SNR-ish check: ratio of RMS to noise floor (very approximate)\n",
        "rms = np.sqrt(np.mean(wav.astype(float)**2))\n",
        "noise_floor = np.percentile(np.abs(wav.astype(float)), 5) + 1e-9\n",
        "print(\"RMS:\", rms, \"Est. noise-floor:\", noise_floor, \"Ratio:\", rms/noise_floor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BQceEbKbSrD"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "input_file = \"sample_voice.wav\"     # change filename if needed\n",
        "output_file = \"processed_voice.wav\"\n",
        "\n",
        "# Load audio\n",
        "audio = AudioSegment.from_file(input_file)\n",
        "\n",
        "# Convert: set frame rate, channels, sample width\n",
        "audio = audio.set_frame_rate(16000)\n",
        "audio = audio.set_channels(1)\n",
        "audio = audio.set_sample_width(2)  # 16-bit PCM\n",
        "\n",
        "# Export\n",
        "audio.export(output_file, format=\"wav\")\n",
        "\n",
        "print(\"Preprocessed file saved as:\", output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFfgaoRGgQfW"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "OpenVoice Complete Setup Script\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "def run_command(command, check=True):\n",
        "    \"\"\"Execute shell command\"\"\"\n",
        "    try:\n",
        "        result = subprocess.run(command, shell=True, check=check, capture_output=True, text=True)\n",
        "        print(result.stdout)\n",
        "        if result.stderr:\n",
        "            print(f\"Stderr: {result.stderr}\")\n",
        "        return result.returncode == 0\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Command failed: {command}\")\n",
        "        print(f\"Error: {e.stderr}\")\n",
        "        return False\n",
        "\n",
        "def main():\n",
        "    print(\"OpenVoice Complete Setup Script\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Step 1: Clone OpenVoice repository if not exists\n",
        "    print(\"\\n[1/4] Checking/Cloning OpenVoice repository...\")\n",
        "    openvoice_path = \"/content/OpenVoice\"\n",
        "\n",
        "    if not os.path.exists(openvoice_path):\n",
        "        print(\"Cloning OpenVoice repository...\")\n",
        "        run_command(\"git clone https://github.com/myshell-ai/OpenVoice.git /content/OpenVoice\")\n",
        "    else:\n",
        "        print(f\"‚úì OpenVoice repository found at {openvoice_path}\")\n",
        "\n",
        "    # Check directory structure\n",
        "    print(\"\\nChecking directory structure...\")\n",
        "    for item in os.listdir(openvoice_path):\n",
        "        print(f\"  - {item}\")\n",
        "\n",
        "    # Step 2: Install dependencies\n",
        "    print(\"\\n[2/4] Installing dependencies...\")\n",
        "    dependencies = [\n",
        "        \"pypinyin\",\n",
        "        \"cn2an\",\n",
        "        \"jieba\",\n",
        "        \"numpy\",\n",
        "        \"scipy\",\n",
        "        \"torch\",\n",
        "        \"torchaudio\",\n",
        "        \"librosa\",\n",
        "        \"matplotlib\",\n",
        "        \"tqdm\"\n",
        "    ]\n",
        "\n",
        "    for dep in dependencies:\n",
        "        print(f\"\\nInstalling {dep}...\")\n",
        "        run_command(f\"pip install {dep}\", check=False)\n",
        "\n",
        "    # Step 3: Install OpenVoice package\n",
        "    print(\"\\n[3/4] Installing OpenVoice as package...\")\n",
        "\n",
        "    # Try to install in development mode\n",
        "    if os.path.exists(os.path.join(openvoice_path, \"setup.py\")):\n",
        "        print(\"Found setup.py, installing in development mode...\")\n",
        "        run_command(f\"cd {openvoice_path} && pip install -e .\", check=False)\n",
        "    else:\n",
        "        print(\"No setup.py found, adding to path manually...\")\n",
        "\n",
        "    # Add to Python path\n",
        "    if openvoice_path not in sys.path:\n",
        "        sys.path.insert(0, openvoice_path)\n",
        "        print(f\"‚úì Added {openvoice_path} to Python path\")\n",
        "\n",
        "    # Step 4: Test imports with multiple attempts\n",
        "    print(\"\\n[4/4] Testing imports...\")\n",
        "\n",
        "    # Try different import approaches\n",
        "    import_attempts = [\n",
        "        # Standard import\n",
        "        \"from openvoice import se_extractor\",\n",
        "        \"from openvoice.api import ToneColorConverter\",\n",
        "\n",
        "        # Alternative imports\n",
        "        \"import openvoice\",\n",
        "        \"from openvoice import api\",\n",
        "\n",
        "        # Direct module access\n",
        "        \"import sys; import os\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\nTesting import paths...\")\n",
        "    print(f\"Current sys.path entries containing 'OpenVoice':\")\n",
        "    for path in sys.path:\n",
        "        if 'OpenVoice' in path:\n",
        "            print(f\"  - {path}\")\n",
        "\n",
        "    print(\"\\nTrying imports...\")\n",
        "\n",
        "    try:\n",
        "        # First check what's in the OpenVoice directory\n",
        "        openvoice_contents = os.listdir(openvoice_path)\n",
        "        print(f\"\\nContents of OpenVoice directory:\")\n",
        "        for item in openvoice_contents:\n",
        "            full_path = os.path.join(openvoice_path, item)\n",
        "            if os.path.isdir(full_path):\n",
        "                print(f\"  üìÅ {item}/\")\n",
        "                subitems = os.listdir(full_path)[:3]  # Show first 3 items\n",
        "                for subitem in subitems:\n",
        "                    print(f\"    - {subitem}\")\n",
        "                if len(os.listdir(full_path)) > 3:\n",
        "                    print(f\"    ... and {len(os.listdir(full_path)) - 3} more\")\n",
        "            else:\n",
        "                print(f\"  üìÑ {item}\")\n",
        "\n",
        "        # Try to find the actual openvoice module\n",
        "        print(\"\\nSearching for Python modules...\")\n",
        "        for root, dirs, files in os.walk(openvoice_path):\n",
        "            if \"__init__.py\" in files:\n",
        "                relative_path = root.replace(openvoice_path, \"\").lstrip(\"/\")\n",
        "                if relative_path:\n",
        "                    print(f\"  Found Python package: {relative_path}\")\n",
        "\n",
        "        # Try importing with the correct path\n",
        "        print(\"\\nTrying to import...\")\n",
        "\n",
        "        # Add the parent directory too\n",
        "        parent_path = \"/content\"\n",
        "        if parent_path not in sys.path:\n",
        "            sys.path.insert(0, parent_path)\n",
        "\n",
        "        # Try importing\n",
        "        import importlib.util\n",
        "\n",
        "        # Check if openvoice module exists\n",
        "        spec = importlib.util.find_spec(\"openvoice\")\n",
        "        if spec is None:\n",
        "            print(\"openvoice module not found in standard locations\")\n",
        "            print(\"\\nTrying manual import...\")\n",
        "\n",
        "            # Look for the actual module\n",
        "            for root, dirs, files in os.walk(openvoice_path):\n",
        "                if \"openvoice\" in root and \"__init__.py\" in files:\n",
        "                    module_path = root\n",
        "                    if module_path not in sys.path:\n",
        "                        sys.path.insert(0, module_path)\n",
        "                    print(f\"Added module path: {module_path}\")\n",
        "\n",
        "        # Final attempt to import\n",
        "        try:\n",
        "            # Try different possible module structures\n",
        "            try:\n",
        "                from openvoice import se_extractor\n",
        "                print(\"‚úì Successfully imported: from openvoice import se_extractor\")\n",
        "            except ImportError:\n",
        "                try:\n",
        "                    import openvoice.se_extractor\n",
        "                    print(\"‚úì Successfully imported: import openvoice.se_extractor\")\n",
        "                except ImportError:\n",
        "                    # Try direct file import\n",
        "                    se_extractor_path = os.path.join(openvoice_path, \"openvoice\", \"se_extractor.py\")\n",
        "                    if os.path.exists(se_extractor_path):\n",
        "                        print(f\"Found se_extractor.py at: {se_extractor_path}\")\n",
        "                        # Add the openvoice directory to path\n",
        "                        openvoice_module_path = os.path.join(openvoice_path, \"openvoice\")\n",
        "                        if os.path.exists(openvoice_module_path):\n",
        "                            if openvoice_module_path not in sys.path:\n",
        "                                sys.path.insert(0, openvoice_module_path)\n",
        "                            print(f\"Added module directory: {openvoice_module_path}\")\n",
        "\n",
        "            print(\"\\n‚úÖ OpenVoice setup completed!\")\n",
        "\n",
        "            # Show usage example\n",
        "            print(\"\\n\" + \"=\" * 60)\n",
        "            print(\"Usage Example:\")\n",
        "            print(\"=\" * 60)\n",
        "            print(\"\"\"\n",
        "# Add to your script:\n",
        "import sys\n",
        "sys.path.insert(0, '/content/OpenVoice')\n",
        "\n",
        "# Then try importing\n",
        "try:\n",
        "    from openvoice import se_extractor\n",
        "    from openvoice.api import ToneColorConverter\n",
        "    print(\"OpenVoice loaded successfully!\")\n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    print(\"Trying alternative import...\")\n",
        "    import openvoice.se_extractor as se_extractor\n",
        "            \"\"\")\n",
        "\n",
        "        except Exception as import_error:\n",
        "            print(f\"Import failed: {import_error}\")\n",
        "            print(\"\\nTroubleshooting steps:\")\n",
        "            print(\"1. Check the directory structure above\")\n",
        "            print(\"2. The 'openvoice' directory should contain __init__.py\")\n",
        "            print(\"3. If structure is different, adjust the import path\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during setup: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEEZXFv1ANod"
      },
      "outputs": [],
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/myshell-ai/OpenVoice openvoice_checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTLOeB2WA_Ls"
      },
      "outputs": [],
      "source": [
        "!find openvoice_checkpoints -name \"config.json\" -o -name \"checkpoint.pth\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68eI-WCbArOy"
      },
      "outputs": [],
      "source": [
        "!mkdir -p checkpoints/converter\n",
        "!cp openvoice_checkpoints/checkpoints/converter/* checkpoints/converter/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKKvvY4SBOoa"
      },
      "outputs": [],
      "source": [
        "!ls -l checkpoints/converter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrBY6en3BYWY"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/OpenVoice')\n",
        "\n",
        "import torch\n",
        "from openvoice.api import ToneColorConverter\n",
        "\n",
        "# Path to converter checkpoints\n",
        "ckpt_converter = \"checkpoints/converter\"\n",
        "\n",
        "# Select device\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Load the converter model\n",
        "tone_color_converter = ToneColorConverter(\n",
        "    f\"{ckpt_converter}/config.json\",\n",
        "    device=device\n",
        ")\n",
        "tone_color_converter.load_ckpt(f\"{ckpt_converter}/checkpoint.pth\")\n",
        "\n",
        "print(\"‚úì ToneColorConverter loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2kplZu7BowS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from openvoice import se_extractor\n",
        "\n",
        "# Your reference audio (16s, clean, processed)\n",
        "audio_file = \"processed_voice.wav\"\n",
        "\n",
        "if not os.path.exists(audio_file):\n",
        "    print(\"‚ùå processed_voice.wav not found in this directory!\")\n",
        "else:\n",
        "    print(\"Found:\", audio_file)\n",
        "\n",
        "    # Extract speaker embedding\n",
        "    target_se, audio_name = se_extractor.get_se(\n",
        "        audio_file,\n",
        "        tone_color_converter,\n",
        "        target_dir='processed',  # temporary dir\n",
        "        vad=True                # removes silence\n",
        "    )\n",
        "\n",
        "    # Save embedding\n",
        "    torch.save(target_se, \"speaker_embedding.pt\")\n",
        "\n",
        "    print(\"\\n‚úÖ Speaker embedding extracted!\")\n",
        "    print(\"Saved as: speaker_embedding.pt\")\n",
        "    print(\"Shape:\", target_se.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m-8Z-CgwDbMw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from openvoice import se_extractor\n",
        "\n",
        "# Reuse the already-loaded tone_color_converter and device\n",
        "# Make sure these exist from previous steps:\n",
        "# - tone_color_converter\n",
        "# - device\n",
        "\n",
        "# 1Ô∏è‚É£ Paths\n",
        "source_audio = \"download (3).mp3\"      # audio whose content you want to convert\n",
        "embedding_path = \"speaker_embedding.pt\"   # your saved target voice embedding\n",
        "output_path = \"converted_voice.wav\"       # output file\n",
        "\n",
        "# 2Ô∏è‚É£ Basic checks\n",
        "if not os.path.exists(source_audio):\n",
        "    raise FileNotFoundError(f\"Source audio not found: {source_audio}\")\n",
        "\n",
        "if not os.path.exists(embedding_path):\n",
        "    raise FileNotFoundError(f\"Speaker embedding not found: {embedding_path}\")\n",
        "\n",
        "print(\"‚úì Found source audio and embedding\")\n",
        "\n",
        "# 3Ô∏è‚É£ Load target speaker embedding\n",
        "tgt_se = torch.load(embedding_path).to(device)\n",
        "print(\"‚úì Loaded target speaker embedding with shape:\", tgt_se.shape)\n",
        "\n",
        "# 4Ô∏è‚É£ Get source speaker embedding (from the same file for now)\n",
        "src_se, _ = se_extractor.get_se(\n",
        "    source_audio,\n",
        "    tone_color_converter,\n",
        "    target_dir='processed_src',\n",
        "    vad=True\n",
        ")\n",
        "src_se = src_se.to(device)\n",
        "print(\"‚úì Extracted source speaker embedding with shape:\", src_se.shape)\n",
        "\n",
        "# 5Ô∏è‚É£ Run conversion\n",
        "print(\"\\nüéß Converting voice...\")\n",
        "tone_color_converter.convert(\n",
        "    audio_src_path=source_audio,\n",
        "    src_se=src_se,\n",
        "    tgt_se=tgt_se,\n",
        "    output_path=output_path,\n",
        "    message=\"Converting voice to target speaker...\"\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Conversion complete! Saved as: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoUl34aYDcWl"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio, display\n",
        "\n",
        "output_path = \"converted_voice.wav\"\n",
        "display(Audio(output_path, autoplay=False))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}