# voyagent---A-budding-mimicking-storyteller-by-Sahasra-Sachi
VoyAgent is a next-generation, voice-driven storytelling model that transforms a single spoken prompt into a cinematic, hyper-personalized narrative experience. It clones the user’s voice using OpenVoice, generates immersive stories with Gemini, and brings them to life with Murf Falcon TTS, seamlessly fused with AI-generated background music.
## Project Overview
VoyAgent is an end-to-end storytelling pipeline that accepts a voice prompt, extracts the user’s vocal identity, generates a tailored narrative using the Gemini LLM, and synthesizes the final story using Murf Falcon TTS in the cloned voice. The output is blended with AI-generated background music to produce a refined, studio-grade audio narrative.

## Setup Instructions


![WhatsApp Image 2025-12-06 at 02 18 15_50ac1f7d](https://github.com/user-attachments/assets/496f7290-fc49-4d50-ab64-22e651d81633)


# Model Setup Instructions

## 1. Install Required Libraries
Install all dependencies needed for VoyAgent, including OpenVoice, Gemini API client, and Murf Falcon SDK.

Example:
pip install -r requirements.txt

## 2. Download OpenVoice Models
Download the OpenVoice base and speaker encoder models and place them in your project directory.

Required files:
- base_speaker_encoder.pt
- vocoder_model.ckpt
- your chosen OpenVoice model folder

Update the model path in your code accordingly.

## 3. Configure API Keys Using Environment Variables
Create a .env file and store all API keys securely:

GEMINI_API_KEY=your_key_here
MURF_API_KEY=your_key_here

Load them in your code using dotenv.

## 4. Provide Source Voice Input
Record or upload a short audio sample (5–15 seconds).  
This audio is used by OpenVoice to extract a speaker embedding.

File example:
source.wav

## 5. Generate Story Prompt
Give the model a spoken prompt such as:
“Tell a 3-minute bedtime story for kids about a brave lion.”

This prompt is transcribed and sent to Gemini for story generation.

## 6. Story Generation with Gemini
The transcribed prompt is processed by the Gemini LLM.  
It outputs a fully structured, personalized story.

## 7. Voice Cloning & TTS
The generated story is converted into speech using:
- OpenVoice (for cloning your voice)
- Murf Falcon TTS (for natural narration)

Output example:
narration_cloned.wav

## 8. Add Background Music
AI-generated ambient/background music is blended with the narration to create a cinematic audio output.

## 9. Final Output
The model produces a fully rendered audio story:
final_story_output.wav



# API Details

## 1. OpenVoice API (Voice Cloning)

### Purpose
Extracts speaker embeddings from a source audio sample and generates cloned-voice speech.
### Main Functions Used
- load_speaker_embedding(source_audio_path)
- generate_speech(text, speaker_embedding, output_path)
### Required Inputs
- source_audio.wav — user’s 5–15 sec voice sample
- target_text.txt — story text generated by the LLM
### Output
- cloned_voice.wav — narration in the user’s cloned voice
### Model Files Needed
- speaker_encoder.pth
- base_generator.pth
- vocoder model files
Ensure model paths are correctly referenced in your code.

## 2. Gemini API (Story Generation)

### Purpose
Processes user’s spoken prompt and generates a structured story.
### Endpoint
Text-generation endpoint (chat or generative model).
### Required Inputs
- prompt: “Tell a 3-minute story for kids about a lion.”
- parameters:
  - language
  - length
  - tone/age group
### Sample Call
content = model.generate_content(prompt)
### Output
- story_text — a complete narrative to pass into TTS
  
## 3. Murf Falcom TTS API (Narration)
### Purpose
Converts the story into high-quality speech.
### Endpoint
TTS synthesis endpoint provided by Murf’s Falcon model.
### Required Inputs
- story_text (from Gemini)
- voice_settings:
  - style
  - pitch
  - speed
  - model type (Falcon Voice)
### Sample Fields
payload = {
  "text": story,
  "voice_id": "falcon",
  "format": "wav"
}

### Output
- murf_output.wav — clean narration audio
(used either directly OR replaced with cloned voice)

## 4. Final Audio Fusion Logic

### Purpose
Blend narration + music into one cohesive output.
### Inputs
- cloned_voice.wav or murf_output.wav
- music.wav
### Output
- final_story_output.wav
Handled using Python audio libraries (pydub or ffmpeg).

## 5. Background Music Generator API (Although didn't synchronize with our model)

### Purpose
Creates ambience that enhances the narration.
### Required Inputs
- mood: calm, cinematic, bedtime, fantasy
- duration: match story length
### Output
- music.wav — background track for final mixing



